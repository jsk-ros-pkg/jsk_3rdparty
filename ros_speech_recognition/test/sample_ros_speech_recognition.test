<launch>
  <!-- launch speech recognition -->

  <arg name="launch_sound_play" default="false" doc="Launch sound_play node to speak" />
  <rosparam>
    <!-- We use rosbag which contains /speech_audio, which many /audio topics stuck together -->
    <!-- Therefore, we need long buffer size for this test -->
    /speech_recognition/buffer_size: 200000
  </rosparam>
  <include file="$(find ros_speech_recognition)/launch/speech_recognition.launch">
    <arg name="launch_sound_play" value="$(arg launch_sound_play)" />
    <arg name="launch_audio_capture" value="false" />
    <arg name="audio_topic" value="/speech_audio" />
    <arg name="language" value="ja" />
    <arg name="continuous" value="true" />
    <arg name="voice_topic" value="/Tablet/voice" />
  </include>

  <!-- launch bag file -->
  <node name="rosbag_play"
        pkg="rosbag" type="play"
        args="$(find ros_speech_recognition)/test/data/konnichiwa.bag --loop">
  </node>

  <test test-name="test_ros_speech_recognition"
        name="test_ros_speech_recognition"
        pkg="jsk_tools"  type="test_topic_published.py" time-limit="120" >
    <rosparam>
      topic_0: /Tablet/voice
      timeout_0: 120
      topic_1: /speech_recognition_candidates_to_string/output
      timeout_1: 120
    </rosparam>
  </test>
</launch>
